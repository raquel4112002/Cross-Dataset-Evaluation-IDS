# Network Intrusion Detection: Traditional ML vs Cross-Dataset Evaluation

Este projeto implementa um sistema completo de detecÃ§Ã£o de intrusÃµes em redes usando modelos de machine learning tradicionais (Random Forest e SVM) com avaliaÃ§Ã£o cross-dataset entre os datasets UNSW-NB15 e CICIDS2017.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Uso](#uso)
- [Resultados](#resultados)
- [Arquivos Gerados](#arquivos-gerados)
- [ContribuiÃ§Ã£o](#contribuiÃ§Ã£o)

## ğŸ¯ VisÃ£o Geral

O projeto compara a performance de modelos tradicionais de machine learning (Random Forest e SVM) para detecÃ§Ã£o de intrusÃµes em redes, com foco especial na transferÃªncia cross-dataset. Utiliza features universais extraÃ­das de ambos os datasets para permitir comparaÃ§Ã£o direta.

### CaracterÃ­sticas Principais

- **Datasets**: UNSW-NB15 e CICIDS2017
- **Modelos**: Random Forest, SVM e Decision Tree
- **Features**: 27 features universais (apÃ³s remoÃ§Ã£o de constantes)
- **Experimentos**: Intra-dataset e Cross-dataset
- **AnÃ¡lise**: MÃ©tricas completas, visualizaÃ§Ãµes e relatÃ³rios para artigos

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8+
- 8GB+ RAM (recomendado para CICIDS2017)
- 10GB+ espaÃ§o em disco

### DependÃªncias

```bash
pip install -r requirements.txt
```

### DependÃªncias Principais

- `pandas` - ManipulaÃ§Ã£o de dados
- `numpy` - ComputaÃ§Ã£o numÃ©rica
- `scikit-learn` - Modelos de ML
- `matplotlib` - VisualizaÃ§Ãµes
- `seaborn` - GrÃ¡ficos estatÃ­sticos
- `tabulate` - FormataÃ§Ã£o de tabelas

## ğŸ“ Estrutura do Projeto

```
cybersecuraty/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ UNSW-NB15/          # Dataset UNSW-NB15
â”‚       â””â”€â”€ CICIDS2017/         # Dataset CICIDS2017
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_corrected.py       # Carregamento e processamento de dados
â”‚   â”œâ”€â”€ data.py                 # Features universais e alinhamento
â”‚   â”œâ”€â”€ experiments.py          # Experimentos intra e cross-dataset
â”‚   â”œâ”€â”€ models.py               # DefiniÃ§Ã£o dos modelos (RF, SVM)
â”‚   â”œâ”€â”€ eval.py                 # AvaliaÃ§Ã£o de mÃ©tricas
â”‚   â”œâ”€â”€ utils.py                # UtilitÃ¡rios
â”‚   â””â”€â”€ kaggle_dl.py           # Download automÃ¡tico de datasets
â”œâ”€â”€ outputs/                    # Resultados dos experimentos
â”œâ”€â”€ outputs_article_analysis/   # AnÃ¡lise completa para artigo
â”œâ”€â”€ main.py                     # Script principal
â”œâ”€â”€ run_article_analysis.py     # AnÃ¡lise detalhada para artigo
â”œâ”€â”€ test_cross.py              # Teste de experimentos cross-dataset
â””â”€â”€ README.md                  # Este arquivo
```

## ğŸ® Uso

### ExecuÃ§Ã£o BÃ¡sica

```bash
# Executar todos os experimentos
python main.py

# Executar apenas anÃ¡lise para artigo
python main.py --run_article_analysis true

# Usar datasets personalizados
python main.py --unsw_dir /path/to/unsw --cicids_dir /path/to/cicids
```

### ParÃ¢metros DisponÃ­veis

```bash
python main.py --help
```

- `--unsw_dir`: DiretÃ³rio do dataset UNSW-NB15
- `--cicids_dir`: DiretÃ³rio do dataset CICIDS2017
- `--gpu`: Usar GPU para XGBoost (se disponÃ­vel)
- `--out_dir`: DiretÃ³rio de saÃ­da
- `--auto_download`: Download automÃ¡tico dos datasets
- `--use_unsw_train_test`: Usar splits oficiais do UNSW
- `--use_cicids_traffic_labelling`: Usar TrafficLabelling do CICIDS
- `--run_article_analysis`: Executar anÃ¡lise completa para artigo

### AnÃ¡lise Detalhada para Artigo

```bash
# Executar apenas a anÃ¡lise para artigo
python run_article_analysis.py
```

## ğŸ“Š Resultados

### Performance Intra-Dataset

| Dataset    | Modelo        | Accuracy | F1-Score | ROC-AUC |
| ---------- | ------------- | -------- | -------- | ------- |
| UNSW-NB15  | Random Forest | 87.8%    | 90.3%    | 98.2%   |
| UNSW-NB15  | SVM           | 74.4%    | 78.0%    | 84.7%   |
| UNSW-NB15  | Decision Tree | 86.3%    | 89.1%    | 96.9%   |
| CICIDS2017 | Random Forest | 83.8%    | 58.3%    | 86.4%   |
| CICIDS2017 | SVM           | 77.8%    | 36.2%    | 90.9%   |
| CICIDS2017 | Decision Tree | 86.6%    | 69.3%    | 78.1%   |

### Performance Cross-Dataset

| TransferÃªncia | Modelo        | F1-Score |
| ------------- | ------------- | -------- |
| UNSW â†’ CICIDS | Random Forest | 4.3%     |
| UNSW â†’ CICIDS | SVM           | 43.1%    |
| UNSW â†’ CICIDS | Decision Tree | 39.5%    |
| CICIDS â†’ UNSW | Random Forest | 0.0%     |
| CICIDS â†’ UNSW | SVM           | 73.0%    |
| CICIDS â†’ UNSW | Decision Tree | 2.3%     |

### Principais Descobertas

1. **Random Forest** tem melhor performance intra-dataset
2. **SVM** tem melhor transferÃªncia cross-dataset
3. **Decision Tree** mostra overfitting mais claramente:
   - **UNSW**: Overfitting controlado (gap 4.5% accuracy)
   - **CICIDS**: Overfitting ALTO (gap 12.1% accuracy)
4. **Cross-dataset transfer** Ã© desafiador, especialmente CICIDS â†’ UNSW
5. **Features universais** (27) sÃ£o eficazes para comparaÃ§Ã£o
6. **Overfitting** Ã© mais severo em datasets desequilibrados (CICIDS)

## ğŸ“ Arquivos Gerados

### outputs/

- MÃ©tricas JSON de cada experimento
- Matrizes de confusÃ£o (PNG)
- Resultados de validaÃ§Ã£o cruzada

### outputs_article_analysis/

- **Tabelas CSV**:
  - `dataset_comparison.csv` - ComparaÃ§Ã£o dos datasets
  - `performance_comparison.csv` - Performance dos modelos
  - `feature_analysis.csv` - AnÃ¡lise das features
- **GrÃ¡ficos PNG**:
  - `class_distribution.png` - DistribuiÃ§Ã£o de classes
  - `performance_comparison.png` - ComparaÃ§Ã£o de performance
  - `cross_dataset_transfer_rf.png` - TransferÃªncia RF
  - `cross_dataset_transfer_svm.png` - TransferÃªncia SVM
  - `cross_dataset_transfer_dt.png` - TransferÃªncia Decision Tree
  - `decision_tree_unsw.png` - VisualizaÃ§Ã£o Decision Tree UNSW
  - `decision_tree_cicids.png` - VisualizaÃ§Ã£o Decision Tree CICIDS
  - `decision_tree_overfitting_analysis.png` - AnÃ¡lise de Overfitting
- **RelatÃ³rio**:
  - `article_report.md` - RelatÃ³rio completo para artigo

## ğŸ”§ Detalhes TÃ©cnicos

### Features Universais (27)

ApÃ³s remoÃ§Ã£o de features constantes, o sistema utiliza:

- **BÃ¡sicas**: duration, total_bytes, total_pkts, mean_pkt_size
- **Forward/Backward**: fwd_bytes, bwd_bytes, fwd_pkts, bwd_pkts
- **Timing**: iat_std
- **Flags**: syn_count, ack_count, flag_sum
- **Rede**: ttl, loss, win
- **EstatÃ­sticas**: pkt_size_std, fwd_bwd_ratio
- **Log**: TransformaÃ§Ãµes logarÃ­tmicas das features principais

### Processamento de Dados

1. **Carregamento**: UNSW usa splits oficiais, CICIDS usa 70/30
2. **Limpeza**: RemoÃ§Ã£o de valores infinitos e NaN
3. **Features**: Engenharia de 39 features â†’ 27 universais
4. **NormalizaÃ§Ã£o**: MinMaxScaler aplicado aos dados combinados
5. **Alinhamento**: Mesmo espaÃ§o de features para cross-dataset

### Modelos

- **Random Forest**: n_estimators=100, max_depth=10, regularizado
- **SVM**: LinearSVC + CalibratedClassifierCV, C=1.0, otimizado
- **Decision Tree**: max_depth=10, min_samples_split=20, regularizado
- **ValidaÃ§Ã£o**: 5-fold StratifiedKFold para mÃ©tricas robustas

## ğŸ“ˆ InterpretaÃ§Ã£o dos Resultados

### Intra-Dataset

- **UNSW**: Dataset mais equilibrado, melhor performance geral
- **CICIDS**: Dataset desequilibrado, desafio para detecÃ§Ã£o de ataques

### Cross-Dataset

- **SVM superior**: Melhor generalizaÃ§Ã£o entre datasets
- **Random Forest limitado**: Overfitting aos padrÃµes especÃ­ficos
- **Decision Tree**: Overfitting severo, especialmente em CICIDS
- **DireÃ§Ã£o importa**: CICIDS â†’ UNSW mais difÃ­cil que UNSW â†’ CICIDS

### AnÃ¡lise de Overfitting

- **UNSW**: Todos os modelos controlam overfitting bem
- **CICIDS**: Decision Tree mostra overfitting severo (12.1% gap accuracy)
- **Random Forest**: Melhor balance entre performance e generalizaÃ§Ã£o
- **SVM**: Mais robusto para cross-dataset transfer

## ğŸš¨ LimitaÃ§Ãµes

1. **Cross-dataset transfer** Ã© naturalmente desafiador
2. **Features universais** podem perder informaÃ§Ã£o especÃ­fica
3. **DesequilÃ­brio de classes** afeta performance
4. **Tempo de execuÃ§Ã£o** longo para datasets grandes

## ğŸ”® Trabalho Futuro

1. **Domain Adaptation**: TÃ©cnicas para melhorar transferÃªncia
2. **Feature Engineering**: Features mais especÃ­ficas por dataset
3. **Ensemble Methods**: CombinaÃ§Ã£o de modelos
4. **Deep Learning**: Redes neurais para comparaÃ§Ã£o
5. **Real-time Detection**: OtimizaÃ§Ã£o para produÃ§Ã£o

## ğŸ“š ReferÃªncias

- UNSW-NB15: Moustafa, N., & Slay, J. (2015)
- CICIDS2017: Sharafaldin, I., et al. (2018)
- Cross-dataset evaluation em IDS: Literatura recente

**Nota**: Este projeto foi desenvolvido para pesquisa acadÃªmica em detecÃ§Ã£o de intrusÃµes em redes. Os resultados sÃ£o vÃ¡lidos para os datasets e configuraÃ§Ãµes especÃ­ficas utilizadas.
